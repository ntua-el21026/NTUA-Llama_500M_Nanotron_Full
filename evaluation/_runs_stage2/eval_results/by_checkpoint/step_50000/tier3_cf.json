{
  "tasks": {
    "arc_easy": {
      "acc": 0.28421052631578947,
      "n": 570
    },
    "commonsense_qa": {
      "acc": 0.2325962325962326,
      "n": 1221
    },
    "copa": {
      "acc": 0.64,
      "n": 100
    },
    "hellaswag": {
      "acc": 0.3194582752439753,
      "n": 10042
    },
    "openbookqa": {
      "acc": 0.284,
      "n": 500
    },
    "piqa": {
      "acc": 0.6664853101196954,
      "n": 1838
    },
    "qasc": {
      "acc": 0.1306695464362851,
      "n": 926
    },
    "sciq": {
      "acc": 0.538,
      "n": 1000
    },
    "social_i_qa": {
      "acc": 0.3930399181166837,
      "n": 1954
    },
    "winogrande": {
      "acc": 0.5122336227308603,
      "n": 1267
    }
  },
  "cf_macro_avg": 0.40006934315595216
}